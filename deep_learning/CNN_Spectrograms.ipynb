{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generate spectrograms\n",
        "\n",
        "The first step is to load the WAV files, use a python package named `Librosa` to generate spectrogram images from them, load the spectrograms into memory and prepare them for use in training a CNN."
      ],
      "metadata": {
        "id": "PX-5pHCLDx7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxfjfh1JDobW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa.display, os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def create_spectrogram(audio_file, image_file):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
        "\n",
        "  y, sr = librosa.load(audio_file)\n",
        "  ms = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "  log_ms = librosa.power_to_db(ms, ref=np.max)\n",
        "  librosa.display.specshow(log_ms, sr=sr)\n",
        "\n",
        "  fig.savefig(image_file)\n",
        "  plt.close(fig)\n",
        "\n",
        "\n",
        "def create_pngs_from_wavs(input_path, output_path):\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "  dir = os.listdir(input_path)\n",
        "\n",
        "  for i, file in enumerate(dir):\n",
        "    input_file = os.path.join(input_path, file)\n",
        "    output_file = os.path.join(output_path, file.split('.')[0] + '.png')\n",
        "    create_spectrogram(input_file, output_file)"
      ]
    }
  ]
}