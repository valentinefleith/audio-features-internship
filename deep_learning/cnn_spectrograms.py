# -*- coding: utf-8 -*-
"""CNN-Spectrograms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NC0D1EHvpArETTmF0W4okeQvYGWmb7fy

First step is connecting to the drive to access corpus audio files.
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Generate spectrograms

The first step is to load the WAV files, use a python package named `Librosa` to generate spectrogram images from them, load the spectrograms into memory and prepare them for use in training a CNN.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import librosa.display, os
import matplotlib.pyplot as plt
# %matplotlib inline

def create_spectrogram(audio_file, image_file):
  fig = plt.figure()
  ax = fig.add_subplot(1,1,1)
  fig.subplots_adjust(left=0,right=1,bottom=0,top=1)

  y, sr = librosa.load(audio_file)
  ms = librosa.feature.melspectrogram(y=y, sr=sr)
  log_ms = librosa.power_to_db(ms, ref=np.max)
  librosa.display.specshow(log_ms, sr=sr)

  fig.savefig(image_file)
  plt.close(fig)


def create_pngs_from_wavs(input_path, output_path):
  if not os.path.exists(output_path):
    os.makedirs(output_path)

  dir = os.listdir(input_path)

  for i, file in enumerate(dir):
    input_file = os.path.join(input_path, file)
    output_file = os.path.join(output_path, file.split('.')[0] + '.png')
    if os.path.exists(output_file):
      continue
    create_spectrogram(input_file, output_file)

for i in range(2, 6):
  create_pngs_from_wavs(f"/content/drive/My Drive/Internship/Audio/{i}", f"/content/drive/My Drive/Internship/Spectrograms/{i}")

"""Check if the number of spectrograms corresponds to the number of audio files:"""

total_len = 0

for i in range(2, 6):
  total_len += len(os.listdir(f'/content/drive/My Drive/Internship/Spectrograms/{i}'))
  if len(os.listdir(f'/content/drive/My Drive/Internship/Spectrograms/{i}')) == len(os.listdir(f'/content/drive/My Drive/Internship/Audio/{i}')):
    print('OK')
  else:
    print('NOT OK')

print(total_len)

"""Declare 2 new helper function for loading and displaying spectrograms. Declare also 2 python lists (1 to store spectrogram images, 1 to store class labels)."""

from keras.preprocessing import image

def load_image_from_path(path, label):
  images = []
  labels = []

  for file in os.listdir(path):
    images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))
    labels.append(label)

  return images, labels

def show_images(images):
  if len(images) < 8:
    fig, axes = plt.subplots(1, len(images), figsize=(20, 20), subplot_kw={'xticks':[], 'yticks':[]})
  else:
    fig, axes = plt.subplots(1, 8, figsize=(20, 20), subplot_kw={'xticks':[], 'yticks':[]})

  for i, ax in enumerate(axes.flat):
    ax.imshow(images[i] / 255)

x = []
y = []

for i in range(2, 6):
  images, labels = load_image_from_path(f'/content/drive/My Drive/Internship/Spectrograms/{i}', i)
  show_images(images)
  x += images
  y += labels

"""Split the images and labels into 2 datasets - one for training and one for testing. Then divide the pixel value by 255 and use Keras's `to_categorical` function."""

from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)

x_train_norm = np.array(x_train) / 255
x_test_norm = np.array(x_test) / 255

y_train_encoded = to_categorical(y_train)
y_test_encoded = to_categorical(y_test)

"""## Build and train the CNN

The next step is to build a CNN containing a series of convolution and pooling layers for feature extraction, a pair of fully connected layers for classification, a softmax layer that outputs probabilities for each class, and to train it with spectrogram images and labels.

First step is defining the CNN.
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dense(6, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""Train the CNN and save the history object returned by fit in a local variable."""

hist = model.fit(x_train_norm, y_train_encoded, epochs=10, validation_data=(x_test_norm, y_test_encoded), batch_size=10)

"""Plot the training and validation accuracy."""

acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, '-', label='Training accuracy')
plt.plot(epochs, val_acc, ':', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

"""## Use of transfer learning to improve accuracy

Using sophisitcated CNNs trained by Google, Microsoft, etc. to be repurposed and used to solve domain-specific problems.
Let's use `MobileNetV2`, a pretrained CNN from Google that is optimized for mobile devices, to extract features from spectrogram images.

We start by calling Keras's MobileNetV2 function to instanciante the model without the classification layers. Then we use the `preprocess_input` fnuction for MobileNet networks and run both datasets througgh MobileNetV2 to extract features.
"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

x_train_norm = preprocess_input(np.array(x_train))
x_test_norm = preprocess_input(np.array(x_test))

train_features = base_model.predict(x_train_norm)
test_features = base_model.predict(x_test_norm)

"""We define a neural network to classify features extracted by MobileNetV2."""

model = Sequential()
model.add(Flatten(input_shape=train_features.shape[1:]))
model.add(Dense(1024, activation='relu'))
model.add(Dense(6, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""Then train the network with features extracted by `MobileNetV2`."""

hist = model.fit(train_features, y_train_encoded, epochs=10, validation_data=(test_features, y_test_encoded), batch_size=10)

"""We plot the training and validation accuracy."""

acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, '-', label='Training accuracy')
plt.plot(epochs, val_acc, ':', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

"""We run the test images through the network and use a confusion matrix to assess the results."""

from sklearn.metrics import confusion_matrix
import seaborn as sns
sns.set()

y_predicted = model.predict(test_features)
mat = confusion_matrix(y_test_encoded.argmax(axis=1), y_predicted.argmax(axis=1))
class_labels = [ '2', '3', '4', '5']
sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted label')
plt.ylabel('True label')